{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Trigiante_Solerte.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNnSZzxgvbr/7uq51rxv7C/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"p-ahydWNO3aZ"},"outputs":[],"source":["!pip install aiohttp\n","!pip install requests\n","!pip install dask[dataframe] --upgrade\n","\n"]},{"cell_type":"code","source":["import dask.dataframe as dd\n","import math"],"metadata":{"id":"u0QlSrtZHSfZ","executionInfo":{"status":"ok","timestamp":1643294825210,"user_tz":-60,"elapsed":3628,"user":{"displayName":"Damiano Solerte","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwMJB6QryGKUqWfo1kR41CmJrl2uFwwuXrkICzBQ=s64","userId":"05868979023795380841"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class BaseDfBench(object):\n","    def __init__(self, df):\n","      self.df = df\n","\n","    def load_dataset(self, path, format, conn=None, **kwargs):\n","        \"\"\"\n","        Load the provided dataframe\n","        \"\"\"\n","        if format == \"csv\":\n","            self.df = self.read_csv(path, **kwargs)\n","        elif format == \"json\":\n","            self.df = self.read_json(path, **kwargs)\n","        elif format == \"xml\":\n","            self.df = self.read_xml(path, **kwargs)\n","        elif format == \"excel\":\n","            self.df = self.read_excel(path, **kwargs)\n","        elif format == \"parquet\":\n","            self.df = self.read_parquet(path, **kwargs)\n","        elif format == \"sql\": \n","            self.df = self.read_sql(path, conn, **kwargs)            \n","        return self.df        \n","        \n","    def read_sql(self, query, conn, **kwargs):\n","        \"\"\"\n","        Given a connection and a query\n","        creates a dataframe from the query output\n","        \"\"\"\n","        self.df = dd.read_sql(query, conn)\n","        return self.df\n","    def read_json(self, path, **kwargs):\n","        \"\"\"\n","        Read a json file\n","        \"\"\"\n","        self.df = dd.read_json(path, **kwargs)\n","        return self.df\n","    \n","    def read_csv(self, path, **kwargs):\n","        \"\"\"\n","        Read a csv file\n","        \"\"\"\n","        self.df = dd.read_csv(path, **kwargs)\n","        return self.df\n","        \n","    def read_xml(self, path, **kwargs):\n","        \"\"\"\n","        Read a xml file\n","        \"\"\"\n","        self.df = dd.read_xml(path, **kwargs)\n","        return self.df\n","        \n","    def read_excel(self, path, **kwargs):\n","        \"\"\"\n","        Read an excel file\n","        \"\"\"\n","        self.df = dd.read_excel(path, **kwargs)\n","        return self.df\n","        \n","    def read_parquet(self, path, **kwargs):\n","        \"\"\"\n","        Read a parquet file\n","        \"\"\"\n","        self.df = dd.read_parquet(path, **kwargs)\n","        return self.df\n","    def sort(self, columns, ascending=True):\n","        \"\"\"\n","        Sort the dataframe by the provided columns\n","        Columns is a list of column names\n","        \"\"\"\n","        self.df = self.df.sort_values(columns, ascending=ascending)\n","        return self.df\n","\n","    def get_columns(self):\n","        \"\"\"\n","        Return the name of the columns in the dataframe\n","        \"\"\"\n","        return list(self.df.columns.values)\n","\n","    def is_unique(self, column):\n","        \"\"\"\n","        Check the uniqueness of all values contained in the provided column_name\n","        \"\"\"\n","        return self.df[column].is_unique\n","\n","    def delete_columns(self, columns):\n","        \"\"\"\n","        Delete the specified columns\n","        Columns is a list of column names\n","        \"\"\"\n","        self.df = self.df.drop(columns=columns)\n","        return self.df\n","\n","    def rename_columns(self, columns):\n","        \"\"\"\n","        Rename the provided columns using the provided names\n","        Columns is a dictionary: {\"column_name\": \"new_name\"}\n","        \"\"\"\n","        self.df = self.df.rename(columns=columns)\n","        return self.df\n","\n","    def merge_columns(self, columns, separator, name):\n","        \"\"\"\n","        Create a new column with the provided name combining the two provided columns using the provided separator\n","        Columns is a list of two column names; separator and name are strings\n","        \"\"\"\n","        self.df[name] = self.df[columns[0]].astype(str) + separator + self.df[columns[1]].astype(str)\n","        return self.df\n","\n","    def fill_nan(self, value):\n","        \"\"\"\n","        Fill nan values in the dataframe with the provided value\n","        \"\"\"\n","        self.df = self.df.fillna(value)\n","        return self.df\n","        \n","    def one_hot_encoding(self, columns):\n","        \"\"\"\n","        Performs one-hot encoding of the provided columns\n","        Columns is a list of column names\n","        \"\"\"\n","        dummies = dd.get_dummies(self.df[columns])\n","        self.df = dd.concat([self.df.drop(columns=columns), dummies], axis=1)\n","        return self.df\n","\n","    def locate_null_values(self, column):\n","        \"\"\"\n","        Returns the rows of the dataframe which contains\n","        null value in the provided column.\n","        \"\"\"\n","        return self.df[self.df[column].isna()]\n","    def search_by_pattern(self, column, pattern):\n","        \"\"\"\n","        Returns the rows of the dataframe which\n","        match with the provided pattern\n","        on the provided column.\n","        Pattern could be a regular expression.\n","        \"\"\"\n","        return self.df[self.df[column].str.contains(re.compile(pattern))]\n","        \n","    def locate_outliers(self, column, lower_quantile=0.1, upper_quantile=0.99):\n","        \"\"\"\n","        Returns the rows of the dataframe that have values\n","        in the provided column lower or higher than the values\n","        of the lower/upper quantile.\n","        \"\"\"\n","        q_low = self.df[column].quantile(lower_quantile)\n","        q_hi  = self.df[column].quantile(upper_quantile)\n","        return self.df[(self.df[column] < q_low) | (self.df[column] > q_hi)]\n","        \n","    def get_columns_types(self):\n","        \"\"\"\n","        Returns a dictionary with column types\n","        \"\"\"\n","        return self.df.dtypes.apply(lambda x: x.name).to_dict()\n","        \n","    def cast_columns_types(self, dtypes):\n","        \"\"\"\n","        Cast the data types of the provided columns \n","        to the provided new data types.\n","        dtypes is a dictionary that provide for each\n","        column to cast the new data type.\n","        \"\"\"\n","        self.df = self.df.astype(dtypes)\n","        return self.df\n","        \n","        \n","    def get_stats(self):\n","        \"\"\"\n","        Returns dataframe statistics.\n","        Only for numeric columns.\n","        Min value, max value, average value, standard deviation, and standard quantiles.\n","        \"\"\"\n","        return self.df.describe()\n","        \n","        \n","        \n","    def find_mismatched_dtypes(self):\n","        \"\"\"\n","        Returns, if exists, a list of columns with mismatched data types.\n","        For example, a column with string dtypes that contains only integer values.\n","        For every columns the list contain an object with three keys:\n","         - Col: name of the column\n","         - current_dtype: current data type\n","         - suggested_dtype: suggested data type\n","        \"\"\"\n","        current_dtypes = self.get_columns_types()\n","        new_dtypes = self.df.apply(pd.to_numeric, axis=1, meta=self.df).dtypes.apply(lambda x: x.name).to_dict()\n","\n","        out = []\n","        for k in current_dtypes.keys():\n","            if new_dtypes[k] != current_dtypes[k]:\n","                out.append({'col': k, 'current_dtype': current_dtypes[k], 'suggested_dtype': new_dtypes[k]})\n","        return out\n","        \n","    def check_allowed_char(self, column, pattern):\n","        \"\"\"\n","        Return true if all the values of the provided column\n","        follow the provided pattern.\n","        For example, if the pattern [a-z] is provided the string\n","        'ciao' will return true, the string 'ciao123' will return false.\n","        \"\"\"\n","        return self.df[column].str.contains(re.compile(pattern)).all()\n","        \n","    def drop_duplicates(self):\n","        \"\"\"\n","        Drop duplicate rows.\n","        \"\"\"\n","        self.df = self.df.drop_duplicates()\n","        return self.df\n","        \n","    def drop_by_pattern(self, column, pattern):\n","        \"\"\"\n","        Delete the rows where the provided pattern\n","        occurs in the provided column.\n","        \"\"\"\n","        matching_rows = self.search_by_pattern(column, pattern)\n","        self.df = self.df.drop(matching_rows.index)\n","        return self.df\n","        \n","    def change_date_time_format(self, column, str_date_time_format):\n","        \"\"\"\n","        Change the date/time format of the provided column\n","        according to the provided formatting string.\n","        column datatype must be datetime\n","        An example of str_date_time_format is '%m/%d/%Y'\n","        \"\"\"\n","        self.df[column] = dd.to_datetime(self.df[column].dt.strftime(str_date_time_format))\n","        return self.df\n","        \n","    def set_header_case(self, case):\n","        \"\"\"\n","        Put dataframe headers in the provided case\n","        Supported cases: \"lower\", \"upper\", \"title\", \"capitalize\", \"swapcase\"\n","        (see definitions in pandas documentation)\n","        \"\"\"\n","        if mode == \"lower\":\n","            self.df.columns = map(str.lower, self.df.columns)\n","        elif mode == \"upper\":\n","            self.df.columns = map(str.upper, self.df.columns)\n","        elif mode == \"title\":\n","            self.df.columns = map(str.title, self.df.columns)\n","        elif mode == \"capitalize\":\n","            self.df.columns = map(str.capitalize, self.df.columns)\n","        elif mode == \"swapcase\":\n","            self.df.columns = map(str.swapcase, self.df.columns)\n","        return self.df\n","\n","    def set_content_case(self, columns, case):\n","        \"\"\"\n","        Put dataframe content in the provided case\n","        Supported cases: \"lower\", \"upper\", \"title\", \"capitalize\", \"swapcase\"\n","        (see definitions in pandas documentation)\n","        Columns is a list of two column names; empty list for the whole dataframe\n","        \"\"\"\n","        if len(columns) == 0:\n","            columns = list(self.df.columns.values)\n","        for column in columns:\n","            if mode == \"lower\":\n","                self.df[column] = self.df[column].str.lower()\n","            elif mode == \"upper\":\n","                self.df[column] = self.df[column].str.upper()\n","            elif mode == \"title\":\n","                self.df[column] = self.df[column].str.title()\n","            elif mode == \"capitalize\":\n","                self.df[column] = self.df[column].str.capitalize()\n","            elif mode == \"swapcase\":\n","                self.df[column] = self.df[column].str.swapcase()\n","        return self.df\n","\n","    def duplicate_columns(self, columns):\n","        \"\"\"\n","        Duplicate the provided columns (add to the dataframe with \"_duplicate\" suffix)\n","        Columns is a list of column names\n","        \"\"\"\n","        for column in columns:\n","            self.df[column + \"_duplicate\"] = self.df[column]\n","        return self.df\n","\n","    def pivot(self, index, columns, values, aggfunc):\n","        \"\"\"\n","        Define the lists of columns to be used as index, columns and values respectively,\n","        and the dictionary to aggregate (\"sum\", \"mean\", \"count\") the values for each column: {\"col1\": \"sum\"}\n","        (see pivot_table in pandas documentation)\n","        \"\"\"\n","        self.df = dd.pivot_table(self.df, index=index, values=values, columns=columns, aggfunc=aggfunc).reset_index()\n","        return self.df\n","\n","    def unpivot(self, columns, var_name, val_name):\n","        \"\"\"\n","        Define the list of columns to be used as values for the variable column,\n","        the name for variable columns and the one for value column_name\n","        \"\"\"\n","        self.df = dd.melt(self.df, id_vars=list(set(list(self.df.columns.values)) - set(columns)), value_vars=columns, var_name=var_name, value_name=val_name)\n","        return self.df\n","\n","    def delete_empty_rows(self, columns):\n","        \"\"\"\n","        Delete the rows with null values for all provided Columns\n","        Columns is a list of column names\n","        \"\"\"\n","        self.df = self.df.dropna(subset = columns, inplace=True)\n","        return self.df\n","\n","    def split(self, column, sep, splits, col_names):\n","        \"\"\"\n","        Split the provided column into splits + 1 columns named after col_names\n","        using the provided sep string as separator\n","        Col_names is a list of column names\n","        \"\"\"\n","        self.df[col_names] = self.df[column].str.split(sep, splits, expand=True)\n","        return self.df\n","\n","    def strip(self, columns, chars):\n","        \"\"\"\n","        Remove the characters appearing in chars at the beginning/end of the provided columns\n","        Columns is a list of column names\n","        \"\"\"\n","        for column in columns:\n","            self.df[column] = self.df[column].str.strip(chars)\n","        return self.df\n","\n","    def remove_diacritics(self, columns):\n","        \"\"\"\n","        Remove diacritics from the provided columns\n","        Columns is a list of column names\n","        \"\"\"\n","        for column in columns:\n","            self.df[column] = self.df[column].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n","        return self.df\n","        \n","    def set_index(self, column):\n","        \"\"\"\n","        Set the provided column as index\n","        \"\"\"\n","        self.df = self.df.set_index(column)\n","        return self.df\n","        \n","        \n","    def change_num_format(self, formats):\n","        \"\"\"\n","        Round one ore more columns to a variable number of decimal places.\n","        formats is a dictionary with the column names as key and the number of decimal places as value.\n","        \"\"\"\n","        self.df = self.df.round(formats)\n","        return self.df\n","        \n","        \n","    def calc_column(self, col_name, f):\n","        \"\"\"\n","        Calculate the new column col_name by applying\n","        the function f\n","        \"\"\"\n","        self.df[col_name] = self.df.apply(f, axis=1)\n","        return self.df\n","        \n","    def join(self, other, left_on=None, right_on=None, how='inner', **kwargs):\n","        \"\"\"\n","        Joins current dataframe (left) with a new one (right).\n","        left_on/right_on are the keys on which perform the equijoin\n","        how is the type of join\n","        **kwargs: additional parameters\n","        \n","        The result is stored in the current dataframe.\n","        \"\"\"\n","        self.df = self.df.merge(other, left_on=left_on, right_on=right_on, how=how, **kwargs)\n","        return self.df\n","        \n","    def groupby(self, columns, f):\n","        \"\"\"\n","        Aggregate the dataframe by the provided columns\n","        then applied the function f on every group\n","        \"\"\"\n","        return self.df.groupby(columns).agg(f)\n","        \n","    \n","    def categorical_encoding(self, columns):\n","        \"\"\"\n","        Convert the categorical values in these columns into numerical values\n","        Columns is a list of column names\n","        \"\"\"\n","        for column in columns:\n","            self.df[column] = self.df[column].astype('category')\n","            self.df[column] = self.df[column].cat.codes\n","        return self.df\n","\n","    def sample_rows(self, frac, num):\n","        \"\"\"\n","        Return a sample of the rows of the dataframe\n","        Frac is a boolean:\n","        - if true, num is the percentage of rows to be returned\n","        - if false, num is the exact number of rows to be returned\n","        \"\"\"\n","        if frac:\n","            return self.df.sample(frac=num/100)\n","        else:\n","            return self.df.sample(n=num)\n","\n","    def append(self, other, ignore_index):\n","        \"\"\"\n","        Append the rows of another dataframe (other) at the end of the provided dataframe\n","        All columns are kept, eventually filled by nan\n","        Ignore index is a boolean: if true, reset row indices\n","        \"\"\"\n","        self.df = self.df.append(other, ignore_index=ignore_index)\n","        return self.df\n","\n","    def replace(self, columns, to_replace, value, regex):\n","        \"\"\"\n","        Replace all occurrencies of to_replace (numeric, string, regex, list, dict) in the provided columns using the provided value\n","        Regex is a boolean: if true, to_replace is interpreted as a regex\n","        Columns is a list of column names\n","        \"\"\"\n","        self.df[columns] = self.df[columns].replace(to_replace=to_replace, value=value, regex=regex)\n","        return self.df\n","\n","    def edit(self, columns, func):\n","        \"\"\"\n","        Edit the values of the cells in the provided columns using the provided expression\n","        Columns is a list of column names\n","        \"\"\"\n","        self.df[columns] = self.df[columns].apply(func)\n","        return self.df\n","\n","    def set_value(self, index, column, value):\n","        \"\"\"\n","        Set the cell identified by index and column to the provided value\n","        \"\"\"\n","        self.df.at[index, column] = value\n","        return self.df\n","\n","    def min_max_scaling(self, columns):\n","        \"\"\"\n","        Independently scale the values in each provided column in the range (0, 1)\n","        Columns is a list of column names\n","        \"\"\"\n","        for column in columns:\n","            self.df[column] = self.df[column] - self.df[column].min()\n","            self.df[column] = self.df[column] / self.df[column].max()\n","            self.df[column] = self.df[column] * (max - min) + min\n","        return self.df\n","\n","    def round(self, columns, n):\n","        \"\"\"\n","        Round the values in columns using n decimal places\n","        Columns is a list of column names\n","        \"\"\"\n","        self.df[columns] = self.df[columns].round(n)\n","        return self.df\n","        \n","    def get_duplicate_columns(self):\n","        \"\"\"\n","        Return a list of duplicate columns, if exists.\n","        Duplicate columns are those which have same values for each row.\n","        \"\"\"\n","        cols = self.df.columns.values\n","        return [(cols[i], cols[j]) for i in range(0, len(cols)) for j in range(i+1, len(cols)) if self.df[cols[i]].equals(self.df[cols[j]])]\n","    \n","    def to_csv(self, path, **kwargs):\n","        \"\"\"\n","        Export the dataframe in a csv file.\n","        \"\"\"\n","        self.df.to_csv(path, **kwargs)\n","        pass\n","        \n","    def query(self, query):\n","        \"\"\"\n","        Queries the dataframe and returns the corresponding\n","        result set.\n","        :param query: a string with the query conditions, e.g. \"col1 > 1 & col2 < 10\"\n","        :return: subset of the dataframe that correspond to the selection conditions\n","        \"\"\"\n","        return self.df.query(query)"],"metadata":{"id":"FsBJJmglTHUD","executionInfo":{"status":"ok","timestamp":1643294830694,"user_tz":-60,"elapsed":132,"user":{"displayName":"Damiano Solerte","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwMJB6QryGKUqWfo1kR41CmJrl2uFwwuXrkICzBQ=s64","userId":"05868979023795380841"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","import pandas as pd\n","\n","\n","path = 'https://dbgroup.ing.unimore.it/invoices/data.zip'\n","!wget -nc 'https://dbgroup.ing.unimore.it/invoices/data.zip'\n","!unzip '/content/data.zip'\n","\n","\n","#dtype={'billing_frequency': 'string','gas_offer': 'float64'}"],"metadata":{"id":"h2pi2UQbCAQN","executionInfo":{"status":"ok","timestamp":1643278557773,"user_tz":-60,"elapsed":188661,"user":{"displayName":"Damiano Solerte","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwMJB6QryGKUqWfo1kR41CmJrl2uFwwuXrkICzBQ=s64","userId":"05868979023795380841"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b21ac07-c2de-41c3-ec28-76825bc521c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-27 10:12:49--  https://dbgroup.ing.unimore.it/invoices/data.zip\n","Resolving dbgroup.ing.unimore.it (dbgroup.ing.unimore.it)... 155.185.48.139\n","Connecting to dbgroup.ing.unimore.it (dbgroup.ing.unimore.it)|155.185.48.139|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1672160143 (1.6G) [application/zip]\n","Saving to: ‘data.zip’\n","\n","data.zip            100%[===================>]   1.56G  17.9MB/s    in 90s     \n","\n","2022-01-27 10:14:20 (17.7 MB/s) - ‘data.zip’ saved [1672160143/1672160143]\n","\n","Archive:  /content/data.zip\n","  inflating: invoices.csv            \n"]}]},{"cell_type":"code","source":["#invoices = dd.read_csv('/content/invoices.csv', dtype={'billing_frequency': 'string', 'gas_offer': 'float64', 'city':'string'}, low_memory=False)\n","invoices = dd.read_csv('invoices.csv', dtype={'billing_frequency': 'string', 'gas_offer': 'float64', 'city':'string'}, low_memory=False)\n","utilities = invoices[['user_code', 'customer_code', 'city', 'address']]\n","customers = invoices[['user_code', 'nominative', 'sex', 'age']]\n","invoices = invoices.drop(labels=['user_code', 'customer_code', 'city', 'address', 'nominative', 'sex', 'age'], axis=1)\n","invoices\n","#(14,15,29,30,31,32,33,36) mixed type"],"metadata":{"id":"tf6lly21Y4bK","executionInfo":{"status":"ok","timestamp":1643294843109,"user_tz":-60,"elapsed":155,"user":{"displayName":"Damiano Solerte","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwMJB6QryGKUqWfo1kR41CmJrl2uFwwuXrkICzBQ=s64","userId":"05868979023795380841"}},"colab":{"base_uri":"https://localhost:8080/","height":292},"outputId":"50a797ab-dfe5-4f53-d3bf-f5ac386071cd"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dask DataFrame Structure:\n","               bill_id   F1_kWh   F2_kWh   F3_kWh    date light_start_date light_end_date      tv gas_amount gas_average_cost light_average_cost emission_date supply_type gas_start_date gas_end_date extra_fees gas_consumption light_consumption gas_offer light_offer_type light_offer howmuch_pay total_amount light_amount average_unit_light_cost average_light_bill_cost average_unit_gas_cost average_gas_bill_cost billing_frequency bill_type gas_system_charges light_system_charges gas_material_cost light_transport_cost gas_transport_cost light_material_cost\n","npartitions=79                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n","                 int64  float64  float64  float64  object           object         object  object     object           object            float64        object      object         object       object     object         float64           float64   float64           object      uint64      object       object       object                  object                  object                object                object            string      bool            float64              float64           float64              float64            float64             float64\n","                   ...      ...      ...      ...     ...              ...            ...     ...        ...              ...                ...           ...         ...            ...          ...        ...             ...               ...       ...              ...         ...         ...          ...          ...                     ...                     ...                   ...                   ...               ...       ...                ...                  ...               ...                  ...                ...                 ...\n","...                ...      ...      ...      ...     ...              ...            ...     ...        ...              ...                ...           ...         ...            ...          ...        ...             ...               ...       ...              ...         ...         ...          ...          ...                     ...                     ...                   ...                   ...               ...       ...                ...                  ...               ...                  ...                ...                 ...\n","                   ...      ...      ...      ...     ...              ...            ...     ...        ...              ...                ...           ...         ...            ...          ...        ...             ...               ...       ...              ...         ...         ...          ...          ...                     ...                     ...                   ...                   ...               ...       ...                ...                  ...               ...                  ...                ...                 ...\n","                   ...      ...      ...      ...     ...              ...            ...     ...        ...              ...                ...           ...         ...            ...          ...        ...             ...               ...       ...              ...         ...         ...          ...          ...                     ...                     ...                   ...                   ...               ...       ...                ...                  ...               ...                  ...                ...                 ...\n","Dask Name: drop_by_shallow_copy, 158 tasks"],"text/html":["<div><strong>Dask DataFrame Structure:</strong></div>\n","<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bill_id</th>\n","      <th>F1_kWh</th>\n","      <th>F2_kWh</th>\n","      <th>F3_kWh</th>\n","      <th>date</th>\n","      <th>light_start_date</th>\n","      <th>light_end_date</th>\n","      <th>tv</th>\n","      <th>gas_amount</th>\n","      <th>gas_average_cost</th>\n","      <th>light_average_cost</th>\n","      <th>emission_date</th>\n","      <th>supply_type</th>\n","      <th>gas_start_date</th>\n","      <th>gas_end_date</th>\n","      <th>extra_fees</th>\n","      <th>gas_consumption</th>\n","      <th>light_consumption</th>\n","      <th>gas_offer</th>\n","      <th>light_offer_type</th>\n","      <th>light_offer</th>\n","      <th>howmuch_pay</th>\n","      <th>total_amount</th>\n","      <th>light_amount</th>\n","      <th>average_unit_light_cost</th>\n","      <th>average_light_bill_cost</th>\n","      <th>average_unit_gas_cost</th>\n","      <th>average_gas_bill_cost</th>\n","      <th>billing_frequency</th>\n","      <th>bill_type</th>\n","      <th>gas_system_charges</th>\n","      <th>light_system_charges</th>\n","      <th>gas_material_cost</th>\n","      <th>light_transport_cost</th>\n","      <th>gas_transport_cost</th>\n","      <th>light_material_cost</th>\n","    </tr>\n","    <tr>\n","      <th>npartitions=79</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th></th>\n","      <td>int64</td>\n","      <td>float64</td>\n","      <td>float64</td>\n","      <td>float64</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>float64</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>float64</td>\n","      <td>float64</td>\n","      <td>float64</td>\n","      <td>object</td>\n","      <td>uint64</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>object</td>\n","      <td>string</td>\n","      <td>bool</td>\n","      <td>float64</td>\n","      <td>float64</td>\n","      <td>float64</td>\n","      <td>float64</td>\n","      <td>float64</td>\n","      <td>float64</td>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","<div>Dask Name: drop_by_shallow_copy, 158 tasks</div>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#Ho normalizzato il tipo dei valori della tassa per la tv, bisogna rendere questo tipo processo automatico in uno dei metodi ed estenderlo alle altre colonne\n","invoices['tv'] = invoices['tv'].str.replace(',', '.').astype(float)\n","invoices['tv'] = invoices['tv'].astype(float)\n","\n","invoices.tv.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tm9aJ3kJRxLJ","executionInfo":{"status":"ok","timestamp":1643294862684,"user_tz":-60,"elapsed":2098,"user":{"displayName":"Damiano Solerte","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwMJB6QryGKUqWfo1kR41CmJrl2uFwwuXrkICzBQ=s64","userId":"05868979023795380841"}},"outputId":"16df743c-7951-4e0b-c6f1-8b4118799306"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0.0\n","1    0.0\n","2    0.0\n","3    0.0\n","4    0.0\n","Name: tv, dtype: float64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["MyBase = BaseDfBench(invoices)\n","format = {\n","    'tv': float\n","}\n","prova = MyBase.change_num_format(format)\n","prova.tv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHudw7KxFmxc","outputId":"6b151b0b-cff2-4f88-e372-6e631a8e904b","executionInfo":{"status":"ok","timestamp":1643279949039,"user_tz":-60,"elapsed":225,"user":{"displayName":"Damiano Solerte","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwMJB6QryGKUqWfo1kR41CmJrl2uFwwuXrkICzBQ=s64","userId":"05868979023795380841"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dask Series Structure:\n","npartitions=10\n","    object\n","       ...\n","     ...  \n","       ...\n","       ...\n","Name: tv, dtype: object\n","Dask Name: getitem, 350 tasks"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["wrongTvFee = invoices['tv'][invoices.tv.isna()]\n","wrongTvFee.npartitions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zaOvp0cL7dxy","executionInfo":{"status":"ok","timestamp":1643212377337,"user_tz":-60,"elapsed":215,"user":{"displayName":"Damiano Solerte","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwMJB6QryGKUqWfo1kR41CmJrl2uFwwuXrkICzBQ=s64","userId":"05868979023795380841"}},"outputId":"73b0e508-078c-44a2-bd4f-3c686dc13251"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["80"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["invoices.tv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ieJLCSme6Wwx","executionInfo":{"status":"ok","timestamp":1643212424667,"user_tz":-60,"elapsed":264,"user":{"displayName":"Damiano Solerte","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwMJB6QryGKUqWfo1kR41CmJrl2uFwwuXrkICzBQ=s64","userId":"05868979023795380841"}},"outputId":"655779d1-c60e-469c-f21c-5a54b462b43f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dask Series Structure:\n","npartitions=80\n","    object\n","       ...\n","     ...  \n","       ...\n","       ...\n","Name: tv, dtype: object\n","Dask Name: getitem, 400 tasks"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":[""],"metadata":{"id":"PTnf_VKDr9w9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["invoices.iloc[:,13:14].compute()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"id":"K_UUwvi_xYMz","executionInfo":{"status":"ok","timestamp":1642441061481,"user_tz":-60,"elapsed":65,"user":{"displayName":"Damiano Solerte","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhwMJB6QryGKUqWfo1kR41CmJrl2uFwwuXrkICzBQ=s64","userId":"05868979023795380841"}},"outputId":"f0c3dfe8-0e7a-4195-dc93-ba98db4dafc4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dask DataFrame Structure:\n","                    tv\n","npartitions=80        \n","                object\n","                   ...\n","...                ...\n","                   ...\n","                   ...\n","Dask Name: getitem, 160 tasks"],"text/html":["<div><strong>Dask DataFrame Structure:</strong></div>\n","<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tv</th>\n","    </tr>\n","    <tr>\n","      <th>npartitions=80</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th></th>\n","      <td>object</td>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <td>...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","<div>Dask Name: getitem, 160 tasks</div>"]},"metadata":{},"execution_count":7}]}]}